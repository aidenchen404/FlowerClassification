{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59fe8fb8-7bac-4a1d-8f77-92a496f17cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported the modules.\n"
     ]
    }
   ],
   "source": [
    "#@title Load the imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# The following lines adjust the granularity of reporting.\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "\n",
    "print(\"Imported the modules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8524577d-a0c4-493a-8eec-7c1e14dd8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")\n",
    "test_df = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_test.csv\")\n",
    "\n",
    "# Scale the labels\n",
    "scale_factor = 1000.0\n",
    "# Scale the training set's label.\n",
    "train_df[\"median_house_value\"] /= scale_factor\n",
    "\n",
    "# Scale the test set's label\n",
    "test_df[\"median_house_value\"] /= scale_factor\n",
    "\n",
    "# Shuffle the examples\n",
    "train_df = train_df.reindex(np.random.permutation(train_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e585cf2a-e217-4897-91ce-1e7917caf26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Input tensors of float values.\n",
    "inputs = {\n",
    "    'latitude':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='latitude'),\n",
    "    'longitude':\n",
    "        tf.keras.layers.Input(shape=(1,), dtype=tf.float32,\n",
    "                              name='longitude')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8fac869-faf3-45c3-9643-84870a308b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the create_model, train_model, and plot_the_loss_curve functions.\n"
     ]
    }
   ],
   "source": [
    "#@title Define functions to create and train a model, and a plotting function\n",
    "def create_model(my_inputs, my_outputs, my_learning_rate):\n",
    "\n",
    "  model = tf.keras.Model(inputs=my_inputs, outputs=my_outputs)\n",
    "\n",
    "  # Construct the layers into a model that TensorFlow can execute.\n",
    "  model.compile(optimizer=tf.keras.optimizers.RMSprop(\n",
    "      learning_rate=my_learning_rate),\n",
    "      loss=\"mean_squared_error\",\n",
    "      metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "def train_model(model, dataset, epochs, batch_size, label_name):\n",
    "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
    "\n",
    "  features = {name:np.array(value) for name, value in dataset.items()}\n",
    "  label = np.array(features.pop(label_name))\n",
    "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True)\n",
    "\n",
    "  # The list of epochs is stored separately from the rest of history.\n",
    "  epochs = history.epoch\n",
    "\n",
    "  # Isolate the mean absolute error for each epoch.\n",
    "  hist = pd.DataFrame(history.history)\n",
    "  rmse = hist[\"root_mean_squared_error\"]\n",
    "\n",
    "  return epochs, rmse\n",
    "\n",
    "\n",
    "def plot_the_loss_curve(epochs, rmse):\n",
    "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Root Mean Squared Error\")\n",
    "\n",
    "  plt.plot(epochs, rmse, label=\"Loss\")\n",
    "  plt.legend()\n",
    "  plt.ylim([rmse.min()*0.94, rmse.max()* 1.05])\n",
    "  plt.show()\n",
    "\n",
    "print(\"Defined the create_model, train_model, and plot_the_loss_curve functions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc3112d9-6349-44f8-be89-a9b2f38f3aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No loss to compute. Provide a `loss` argument in `compile()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 26\u001b[0m\n\u001b[0;32m     18\u001b[0m my_model \u001b[38;5;241m=\u001b[39m create_model(inputs, outputs, learning_rate)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# To view a PNG of this model's layers, uncomment the call to\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# `tf.keras.utils.plot_model` below. After running this code cell, click\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# the file folder on the left, then the `my_model.png` file.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# tf.keras.utils.plot_model(my_model, \"my_model.png\", show_shapes=True)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Train the model on the training set.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m epochs, rmse \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Print out the model summary.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m my_model\u001b[38;5;241m.\u001b[39msummary(expand_nested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataset, epochs, batch_size, label_name)\u001b[0m\n\u001b[0;32m     18\u001b[0m features \u001b[38;5;241m=\u001b[39m {name:np\u001b[38;5;241m.\u001b[39marray(value) \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     19\u001b[0m label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(features\u001b[38;5;241m.\u001b[39mpop(label_name))\n\u001b[1;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# The list of epochs is stored separately from the rest of history.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m epochs \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mepoch\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py:331\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    329\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39msum(ops\u001b[38;5;241m.\u001b[39mcast(loss, dtype\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mfloatx())))\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mbackend() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(losses) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo loss to compute. Provide a `loss` argument in `compile()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    333\u001b[0m     )\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(losses) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    335\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m losses[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: No loss to compute. Provide a `loss` argument in `compile()`."
     ]
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.05\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "label_name = 'median_house_value'\n",
    "\n",
    "# The two Input layers are concatenated so they can be passed as a single\n",
    "# tensor to a Dense layer.\n",
    "preprocessing_layer = tf.keras.layers.Concatenate()(list(inputs.values()))\n",
    "\n",
    "dense_output = layers.Dense(units=1, name='dense_layer')(preprocessing_layer)\n",
    "\n",
    "outputs = {\n",
    "  'dense_output': dense_output\n",
    "}\n",
    "\n",
    "# Create and compile the model's topography.\n",
    "my_model = create_model(inputs, outputs, learning_rate)\n",
    "\n",
    "# To view a PNG of this model's layers, uncomment the call to\n",
    "# `tf.keras.utils.plot_model` below. After running this code cell, click\n",
    "# the file folder on the left, then the `my_model.png` file.\n",
    "# tf.keras.utils.plot_model(my_model, \"my_model.png\", show_shapes=True)\n",
    "\n",
    "# Train the model on the training set.\n",
    "epochs, rmse = train_model(my_model, train_df, epochs, batch_size, label_name)\n",
    "\n",
    "# Print out the model summary.\n",
    "my_model.summary(expand_nested=True)\n",
    "\n",
    "plot_the_loss_curve(epochs, rmse)\n",
    "\n",
    "print(\"\\n: Evaluate the new model against the test set:\")\n",
    "test_features = {name:np.array(value) for name, value in test_df.items()}\n",
    "test_label = np.array(test_features.pop(label_name))\n",
    "my_model.evaluate(x=test_features, y=test_label, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e9cf9d-0196-44db-af86-80d5a1dfc7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
